# wtf.ai
Where to find buddy


I am excited to present to you an omniscient app that can answer all your questions. This app is powered by a state-of-the-art large language model called LlAMa, which is based on the GPT(Generative Pre-trained Transformer) architecture.

In this presentation, we will cover the following topics:

1. Overview of the wtf.ai app
2. How the app works
3. Benefi
of using the app
4. Overview of LlAMa
5.  Risks
6.  Under Lying Architecture

Let's get started.

## 1. Overview of the wff.ai where to find ? 

The wtf.ai team has been involved in the development of the omniscient app.  this team contributed custom data to train the LlAMa model, which allows it to answer a wide range of questions with a high degree of accuracy.

## 2. How the app works

The app works by using the LlAMaIndex (GPT Index) to connect the LlAMa model with external data. This allows the model to answer a wide range of questions with a high degree of accuracy. To use the app, 
  
  1. Copy or drop the custom knowledge base like confluence,share point documents or  any unstrustured data of knowledge base files (i.e. ppt,pdf,.txt,chats,html etc.. ) under data folder
  2. Train the model with your custom data our app will fine tune the model with updated knowledge base 
  3.  Ask your  questions
  4. App will use the gpt interface index to anser your question from the fine tuned index model 
  5. If the documents/content  gets updated train the model using this app 
  6. simply input your question and wait for the model to generate an answer.

## 3. Benefits of using the app

There are many benefits to using the omniscient app. For example:

It can save you time and effort by providing quick answers to your questions.
It can help you learn new things by providing accurate and detailed information.
It can improve your productivity by allowing you to focus on more important tasks.

## 4. Overview of LlAMa 

LlAMa is a state-of-the-art large language model based on the GPT(Generative Pre-trained Transformer) architecture. Specifically, it is a fine-tuned version of the GPT-3 model, which can run on your local computer. LlamaHub.ai provides a central interface in the form of a custom indexing system called LlamaIndex (GPT Index), which enables you to connect your large language models with external data. This allows you to index your data for various tasks, such as text generation, summarization, question answering, and more.

In conclusion, the omniscient app powered by LlAMa is a powerful tool that can answer all your questions. It is easy to use and provides accurate information, thanks to the wtf.ai team's contributions and the LlamaHub.ai platform. If you have any questions, I highly recommend giving the app a try. Thank you.
Its an Omniscient app which answer all your questions

## 5. Risks
  1. Bias: The custom data used for training the model may have inherent biases that can be carried over into the model's responses. This can lead to biased and inaccurate answers to certain types of questions.

  2. Privacy concerns: Depending on the nature of the custom data used for training, there may be privacy concerns. For example, if the data includes sensitive information such as personal details, it could potentially be exposed through the model's responses.

  3. Malicious content: If the custom data used for training contains malicious or harmful content, the model's responses could also contain such content.

  4. Overfitting: If the model is trained on a limited dataset, it may overfit to that dataset and perform poorly on new data. This can lead to inaccurate answers to questions outside the scope of the training data.

To mitigate these risks, it is important to carefully select and preprocess the custom data used for training, and to continuously monitor and evaluate the model's performance. Additionally, it is important to ensure that the model is only used for appropriate and ethical purposes.

## 6. Architecture
  Llama is based on the Transformer neural network architecture, which is a type of deep learning architecture specifically designed for natural language processing (NLP) tasks. The Transformer architecture was introduced in a 2017 paper by Vaswani et al. and has since become a popular choice for a wide range of NLP    tasks due to its superior performance.

   The Transformer architecture is characterized by its use of self-attention mechanisms, which allow it to capture the dependencies between words in a sentence more effectively than traditional recurrent neural networks (RNNs). The architecture consists of an encoder and a decoder, each of which is composed of multiple layers of self-attention and feedforward neural networks.

  Llama is a fine-tuned version of the GPT-3 model, which is one of the largest and most advanced language models based on the Transformer architecture. The fine-tuning process involves training the model on additional data to improve its performance on specific tasks, such as question answering. The wtf.ai team has contributed custom data to train Llama and make it more effective at answering questions



 
